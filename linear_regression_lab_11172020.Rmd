---
title: "Week 6 Coding Lesson"
author: "Adriane McDonald"
date: "11/17/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#1. DIY Coding Lesson

Intro to Linear Regression

Load all required packages: tidyverse, palmerpenguins, ggpubr, and broom

```{r}
library(tidyverse)
library(palmerpenguins)
library(ggpubr)
library(broom)
```

#2. Rank-based test example (Mann Whitney U)

The Mann Whitney U is used to compare ranks (medians) between two unpaired samples (non-parametric alternative to two-sample t-test)

Creating two sample vectors

set.seed is used to create a pseudorandom sample so we all get the same samples 

sample.int() is used to create random samples with integers from 1 to x of size = ?

```{r}
set.seed(1414)
gp_1 <-sample.int(20, size = 15, replace = TRUE)

set.seed(1424)
gp_2<- sample.int(30, size = 15, replace = TRUE)
```

Do exploratory data visualization 

```{r}
hist(gp_1)
```

```{r}
hist(gp_2)
```

Perform Mann-Whitney U to answer if there is a significant difference in ranks (medians) between gp_1 and gp_2 using the wilcox.test() function.

```{r}
my_mwu <- wilcox.test(gp_1, gp_2)
```

P-value was calculated to be 0.28, which means that if the null hypothesis is true(these samples were drawn from populations with the same median), there is a probability of 0.28 that we could have found median values at least as different as ours by chance. 

Not sufficient evidence to reject the null hypothesis of equal ranks (or medians) using a significance level of 0.05. 

Use ?kruskal.test for more info about a rank-based test for comparing medians across >2 groups 

#3. Simple Linear Regression

Explore the relationship between flipper length and body mass for penguins, including all 3 penguin species included in the penguins dataset 

### A. Make sure to look at the dataset

```{r}
ggplot(data = penguins, aes(x = flipper_length_mm, y = body_mass_g))+
  geom_point()
```

Ask questions about our exploratory visualization:
- Does it look like a linear relationship makes sense?
- Do we have any concerns about modeling as a linear relationship?
- Any notable outliers?
- Initial thoughts about homoscedasticity?

### B. Model it. 

modeled using lm()

```{r}
penguin_lm <- lm(body_mass_g ~ flipper_length_mm, data = penguins)

summary(penguin_lm)
```

Both the intercept and flipper_length_mm coefficients are significantly different from zero 

The Multiple R^2 value is 0.759 meaning that 75.9% of variance in body mass is explained by flipper length

###C. Access model outputs

full equation is mass = 49.69*(flipper length) + (-5780.83)

Use broom::tidy function to get the model outputs in nice data frame format:

```{r}
penguin_lm_tidy <- broom::tidy(penguin_lm)
```

Some other examples:

```{r}
#Get the intercept:

penguin_int <- penguin_lm_tidy$estimate[1]
penguin_int
```

```{r}
#Get the flipper_length coefficient:

penguin_coef <- penguin_lm_tidy$estimate[2]
penguin_coef
```

Some ofther model information can be degrees of freedom, F-statistic, p-value, etc.

Statistical outcomes can be accessed using broom::glance()

```{r}
penguin_lm_out <- broom::glance(penguin_lm)
penguin_lm_out
```

Can use the results of both to write a statement about the model that will automatically update if anything about the model changes. You can also reference outputs automatically in text. Example:

Simple linear regression was used to explore the relationship between penguin flipper length (mm) and body mass (g) across all three penguin species, and including both male and female penguins. A significant regression model was found ($/beta$ = 'r round(penguin_coef, 3)', F('r penguin_lm_out$df','r penguin_lm_out$df.residual') = 'r round(penguin_lm_out$statistic, 1)', p < 0.001) with an R^2^ of 'r found(penguin_lm_out$r.squared,3)'."

###D. Explore model assumptions

Still have assumptions for linear regression to explore, some related to the residuals:

- Lineraly related variables (CHECK)
- Normally distributed residuals
- Homoscedasticity (constant residuals variance)
- iid residuals (no serial correlation)- more often a concern in time series data

Plot the model. This will automatically create four useful visualizations to consider assumptions!

```{r}
plot(penguin_lm)
```

Found plots show up here:

- **The first one:** fitted values vs. resuduals
- **The second one:** QQ-plot for residuals
- **The third one:** another way of looking at fitted vs. residuals
- **The fourth one:** Cook's distance, a measure of influence or leverage that individual points have on the model-often considered a way to explore outliers. 

###E. Visualize the model

Now have decided that linear regression is a valid tool to describe the relationship between flipper length and body mass

- Use 'geom_smooth(method = "lm")' to add a linear model to an existing scatterplot
- Use 'stat_cor()' and/or 'stat_regline_equation()' to add equation information directly to the plot panel, at an x- and y- position that you specify 

```{r}
ggplot(data = penguins, aes(x = flipper_length_mm, y = body_mass_g))+
  geom_point(size = 1)+
  geom_smooth(method = "lm",
              color = "lightgreen",
              size = 0.5,
              fill = "blueviolet",
              alpha = 0.7)+
  theme_light()+
  ggpubr::stat_regline_equation(label.x = 180, label.y = 5700)
```


###F. Find Pearson's r for correlation:

Coefficient of determination, R^2^, tells us how much of the variance in the dependent variable is explained by the model. 

Might also want to explore the strength of the correlation (degree of relationship) between two variables which, for two linearly related continuous variables, can be expressed using Pearson's *r*. 

Pearson's *r* ranges in value from -1 (perfectly negatively correlated - as one variable increases the other decreases) to 1 (perfectly positively correlated - as one variable increases the other increases). A correlation of 0 means that there is no degree of relationship between the two variables. 

Typical guidelines look something like this: 

- r = 0: no correlation
- r < |0.3|: weak correlation
- r between |0.3| and |0.7|: moderate correlation
- r > |0.7|: strong correlation

Use cor.test() function, adding two vectors (flipper_length_mm and body_mass) as the arguments. The function reports the Pearson's r value, and performs a hypothesis test with null hypothesis that the correlation = 0. 

```{r}
penguins_cor <- cor.test(penguins$flipper_length_mm, penguins$body_mass_g)

penguins_cor
```






















